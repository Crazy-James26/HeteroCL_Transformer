

================================================================
== Vitis HLS Report for 'Attention_layer'
================================================================
* Date:           Sun Sep  3 07:19:49 2023

* Version:        2022.1.2 (Build 3605665 on Fri Aug  5 22:52:02 MDT 2022)
* Project:        out.prj
* Solution:       solution1 (Vivado IP Flow Target)
* Product family: zynq
* Target device:  xc7z020-clg484-1


================================================================
== Performance Estimates
================================================================
+ Timing: 
    * Summary: 
    +--------+----------+----------+------------+
    |  Clock |  Target  | Estimated| Uncertainty|
    +--------+----------+----------+------------+
    |ap_clk  |  10.00 ns|  6.972 ns|     2.70 ns|
    +--------+----------+----------+------------+

+ Latency: 
    * Summary: 
    +---------+---------+----------+----------+-----+-----+---------+
    |  Latency (cycles) |  Latency (absolute) |  Interval | Pipeline|
    |   min   |   max   |    min   |    max   | min | max |   Type  |
    +---------+---------+----------+----------+-----+-----+---------+
    |      891|      891|  8.910 us|  8.910 us|  891|  891|       no|
    +---------+---------+----------+----------+-----+-----+---------+

    + Detail: 
        * Instance: 
        +--------------------------------------------------------------------+----------------------------------------------------------+---------+---------+----------+----------+-----+-----+---------+
        |                                                                    |                                                          |  Latency (cycles) |  Latency (absolute) |  Interval | Pipeline|
        |                              Instance                              |                          Module                          |   min   |   max   |    min   |    max   | min | max |   Type  |
        +--------------------------------------------------------------------+----------------------------------------------------------+---------+---------+----------+----------+-----+-----+---------+
        |grp_Attention_layer_Pipeline_VITIS_LOOP_60_1_VITIS_LOOP_61_2_fu_20  |Attention_layer_Pipeline_VITIS_LOOP_60_1_VITIS_LOOP_61_2  |      146|      146|  1.460 us|  1.460 us|  146|  146|       no|
        |grp_Attention_layer_Pipeline_VITIS_LOOP_65_3_VITIS_LOOP_66_4_fu_26  |Attention_layer_Pipeline_VITIS_LOOP_65_3_VITIS_LOOP_66_4  |      146|      146|  1.460 us|  1.460 us|  146|  146|       no|
        |grp_Attention_layer_Pipeline_l_gemm_i2_l_j2_fu_32                   |Attention_layer_Pipeline_l_gemm_i2_l_j2                   |      584|      584|  5.840 us|  5.840 us|  584|  584|       no|
        |grp_Attention_layer_Pipeline_l_norm_i3_l_j3_fu_41                   |Attention_layer_Pipeline_l_norm_i3_l_j3                   |      156|      156|  1.560 us|  1.560 us|  156|  156|       no|
        +--------------------------------------------------------------------+----------------------------------------------------------+---------+---------+----------+----------+-----+-----+---------+

        * Loop: 
        N/A

============================================================
+ Verbose Summary: Synthesis Manager
============================================================
InlineROM: 1
ExposeGlobal: 0
============================================================
+ Verbose Summary: CDFG Model
============================================================
IsTopModel: 0
ResetActiveHigh: 1
IsCombinational: 0
IsDatapathOnly: 0
HasWiredReturn: 1
HasMFsm: 0
HasVarLatency: 1
IsPipeline: 0
IsRtlPipelined: 0
IsInstanceOverlapped: 0
IsDontTouch: 0
HasImplIP: 0
IsGatedGlobalClock: 0


============================================================
+ Verbose Summary: Schedule
============================================================
* Number of FSM states : 6
* Pipeline : 0
* Dataflow Pipeline: 0

* FSM state transitions: 
1 --> 2 
2 --> 3 
3 --> 4 
4 --> 5 
5 --> 6 
6 --> 

* FSM state operations: 

State 1 <SV = 0> <Delay = 3.25>
ST_1 : Operation 7 [1/1] (3.25ns)   --->   "%outp_V = alloca i64 1" [kernel.cpp:59]   --->   Operation 7 'alloca' 'outp_V' <Predicate = true> <Delay = 3.25>
ST_1 : Operation 8 [2/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_VITIS_LOOP_60_1_VITIS_LOOP_61_2, i24 %outp_V"   --->   Operation 8 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >
ST_1 : Operation 9 [2/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_VITIS_LOOP_65_3_VITIS_LOOP_66_4, i32 %v25"   --->   Operation 9 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 2 <SV = 1> <Delay = 0.00>
ST_2 : Operation 10 [1/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_VITIS_LOOP_60_1_VITIS_LOOP_61_2, i24 %outp_V"   --->   Operation 10 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >
ST_2 : Operation 11 [1/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_VITIS_LOOP_65_3_VITIS_LOOP_66_4, i32 %v25"   --->   Operation 11 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 3 <SV = 2> <Delay = 0.00>
ST_3 : Operation 12 [2/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_l_gemm_i2_l_j2, i24 %v23, i24 %v24, i24 %outp_V"   --->   Operation 12 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 4 <SV = 3> <Delay = 0.00>
ST_4 : Operation 13 [1/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_l_gemm_i2_l_j2, i24 %v23, i24 %v24, i24 %outp_V"   --->   Operation 13 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 5 <SV = 4> <Delay = 0.00>
ST_5 : Operation 14 [2/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_l_norm_i3_l_j3, i32 %v25, i24 %outp_V"   --->   Operation 14 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 6 <SV = 5> <Delay = 0.00>
ST_6 : Operation 15 [1/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_l_norm_i3_l_j3, i32 %v25, i24 %outp_V"   --->   Operation 15 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >
ST_6 : Operation 16 [1/1] (0.00ns)   --->   "%ret_ln93 = ret" [kernel.cpp:93]   --->   Operation 16 'ret' 'ret_ln93' <Predicate = true> <Delay = 0.00>


============================================================
+ Verbose Summary: Binding
============================================================
STG Binding: 
---------------- STG Properties BEGIN ----------------
- Is combinational: 0
- Is one-state seq: 0
- Is datapath-only: 0
- Is pipelined: 0
- Is top level: 0
Port [ Return ] is wired: 1; IO mode=ap_ctrl_hs:ce=0
Port [ v23]:  wired=1; compound=1; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[11111111111111113]; IO mode=ap_memory:ce=0
Port [ v24]:  wired=1; compound=1; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[11111111111111113]; IO mode=ap_memory:ce=0
Port [ v25]:  wired=1; compound=1; hidden=0; nouse=0; global=0; static=0; extern=0; dir=1; type=1; pingpong=0; private_global=0; MemPort=[03]; IO mode=ap_memory:ce=0
---------------- STG Properties END ------------------

---------------- Datapath Model BEGIN ----------------

<LifeTime>
<method=bitvector/>
outp_V   (alloca) [ 0011111]
call_ln0 (call  ) [ 0000000]
call_ln0 (call  ) [ 0000000]
call_ln0 (call  ) [ 0000000]
call_ln0 (call  ) [ 0000000]
ret_ln93 (ret   ) [ 0000000]
</LifeTime>

<model>

<comp_list>
<comp id="0" class="1000" name="v23">
<pin_list>
<pin id="1" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="v23"/><MemPortTyVec>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="2" class="1000" name="v24">
<pin_list>
<pin id="3" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="v24"/><MemPortTyVec>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="4" class="1000" name="v25">
<pin_list>
<pin id="5" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="v25"/><MemPortTyVec>0 3 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="6" class="1001" name="const_6">
<pin_list>
<pin id="7" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="8" class="1001" name="const_8">
<pin_list>
<pin id="9" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="Attention_layer_Pipeline_VITIS_LOOP_60_1_VITIS_LOOP_61_2"/></StgValue>
</bind>
</comp>

<comp id="10" class="1001" name="const_10">
<pin_list>
<pin id="11" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="Attention_layer_Pipeline_VITIS_LOOP_65_3_VITIS_LOOP_66_4"/></StgValue>
</bind>
</comp>

<comp id="12" class="1001" name="const_12">
<pin_list>
<pin id="13" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="Attention_layer_Pipeline_l_gemm_i2_l_j2"/></StgValue>
</bind>
</comp>

<comp id="14" class="1001" name="const_14">
<pin_list>
<pin id="15" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="Attention_layer_Pipeline_l_norm_i3_l_j3"/></StgValue>
</bind>
</comp>

<comp id="16" class="1004" name="outp_V_alloca_fu_16">
<pin_list>
<pin id="17" dir="0" index="0" bw="1" slack="0"/>
<pin id="18" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V/1 "/>
</bind>
</comp>

<comp id="20" class="1004" name="grp_Attention_layer_Pipeline_VITIS_LOOP_60_1_VITIS_LOOP_61_2_fu_20">
<pin_list>
<pin id="21" dir="0" index="0" bw="0" slack="0"/>
<pin id="22" dir="0" index="1" bw="24" slack="0"/>
<pin id="23" dir="1" index="2" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/1 "/>
</bind>
</comp>

<comp id="26" class="1004" name="grp_Attention_layer_Pipeline_VITIS_LOOP_65_3_VITIS_LOOP_66_4_fu_26">
<pin_list>
<pin id="27" dir="0" index="0" bw="0" slack="0"/>
<pin id="28" dir="0" index="1" bw="32" slack="0"/>
<pin id="29" dir="1" index="2" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/1 "/>
</bind>
</comp>

<comp id="32" class="1004" name="grp_Attention_layer_Pipeline_l_gemm_i2_l_j2_fu_32">
<pin_list>
<pin id="33" dir="0" index="0" bw="0" slack="0"/>
<pin id="34" dir="0" index="1" bw="24" slack="0"/>
<pin id="35" dir="0" index="2" bw="24" slack="0"/>
<pin id="36" dir="0" index="3" bw="24" slack="2147483647"/>
<pin id="37" dir="1" index="4" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/3 "/>
</bind>
</comp>

<comp id="41" class="1004" name="grp_Attention_layer_Pipeline_l_norm_i3_l_j3_fu_41">
<pin_list>
<pin id="42" dir="0" index="0" bw="0" slack="0"/>
<pin id="43" dir="0" index="1" bw="32" slack="0"/>
<pin id="44" dir="0" index="2" bw="24" slack="2147483647"/>
<pin id="45" dir="1" index="3" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/5 "/>
</bind>
</comp>

</comp_list>

<net_list>
<net id="19"><net_src comp="6" pin="0"/><net_sink comp="16" pin=0"/></net>

<net id="24"><net_src comp="8" pin="0"/><net_sink comp="20" pin=0"/></net>

<net id="25"><net_src comp="16" pin="1"/><net_sink comp="20" pin=1"/></net>

<net id="30"><net_src comp="10" pin="0"/><net_sink comp="26" pin=0"/></net>

<net id="31"><net_src comp="4" pin="0"/><net_sink comp="26" pin=1"/></net>

<net id="38"><net_src comp="12" pin="0"/><net_sink comp="32" pin=0"/></net>

<net id="39"><net_src comp="0" pin="0"/><net_sink comp="32" pin=1"/></net>

<net id="40"><net_src comp="2" pin="0"/><net_sink comp="32" pin=2"/></net>

<net id="46"><net_src comp="14" pin="0"/><net_sink comp="41" pin=0"/></net>

<net id="47"><net_src comp="4" pin="0"/><net_sink comp="41" pin=1"/></net>

</net_list>

</model> 
---------------- Datapath Model END ------------------

* FSMD analyzer results:
  - Output states:
	Port: v25 | {1 2 5 6 }
 - Input state : 
	Port: Attention_layer : v23 | {3 4 }
	Port: Attention_layer : v24 | {3 4 }
  - Chain level:
	State 1
		call_ln0 : 1
	State 2
	State 3
	State 4
	State 5
	State 6


============================================================
+ Verbose Summary: Datapath Resource usage 
============================================================

* Functional unit list:
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
| Operation|                           Functional Unit                          |   DSP   |  Delay  |    FF   |   LUT   |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|          | grp_Attention_layer_Pipeline_VITIS_LOOP_60_1_VITIS_LOOP_61_2_fu_20 |    0    |    0    |    24   |    85   |
|   call   | grp_Attention_layer_Pipeline_VITIS_LOOP_65_3_VITIS_LOOP_66_4_fu_26 |    0    |    0    |    24   |    85   |
|          |          grp_Attention_layer_Pipeline_l_gemm_i2_l_j2_fu_32         |   256   | 354.798 |  26084  |  10042  |
|          |          grp_Attention_layer_Pipeline_l_norm_i3_l_j3_fu_41         |    3    |  3.176  |   522   |   1178  |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|   Total  |                                                                    |   259   | 357.974 |  26654  |  11390  |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|

Memories:
+------+--------+--------+--------+--------+
|      |  BRAM  |   FF   |   LUT  |  URAM  |
+------+--------+--------+--------+--------+
|outp_V|    1   |    0   |    0   |    0   |
+------+--------+--------+--------+--------+
| Total|    1   |    0   |    0   |    0   |
+------+--------+--------+--------+--------+

* Register list:
N/A

* Multiplexer (MUX) list: 
|--------|------|------|------|--------|
|  Comp  |  Pin | Size |  BW  | S x BW |
|--------|------|------|------|--------|
|  Total |      |      |      |    0   |
|--------|------|------|------|--------|



* Summary:
+-----------+--------+--------+--------+--------+--------+--------+
|           |  BRAM  |   DSP  |  Delay |   FF   |   LUT  |  URAM  |
+-----------+--------+--------+--------+--------+--------+--------+
|  Function |    -   |   259  |   357  |  26654 |  11390 |    -   |
|   Memory  |    1   |    -   |    -   |    0   |    0   |    0   |
|Multiplexer|    -   |    -   |    -   |    -   |    -   |    -   |
|  Register |    -   |    -   |    -   |    -   |    -   |    -   |
+-----------+--------+--------+--------+--------+--------+--------+
|   Total   |    1   |   259  |   357  |  26654 |  11390 |    0   |
+-----------+--------+--------+--------+--------+--------+--------+
