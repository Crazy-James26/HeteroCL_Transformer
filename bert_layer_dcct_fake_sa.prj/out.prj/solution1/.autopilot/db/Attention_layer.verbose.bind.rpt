

================================================================
== Vitis HLS Report for 'Attention_layer'
================================================================
* Date:           Tue Sep  5 02:10:17 2023

* Version:        2022.1.2 (Build 3605665 on Fri Aug  5 22:52:02 MDT 2022)
* Project:        out.prj
* Solution:       solution1 (Vivado IP Flow Target)
* Product family: zynq
* Target device:  xc7z020-clg484-1


================================================================
== Performance Estimates
================================================================
+ Timing: 
    * Summary: 
    +--------+----------+----------+------------+
    |  Clock |  Target  | Estimated| Uncertainty|
    +--------+----------+----------+------------+
    |ap_clk  |  10.00 ns|  7.090 ns|     2.70 ns|
    +--------+----------+----------+------------+

+ Latency: 
    * Summary: 
    +---------+---------+----------+----------+-----+-----+---------+
    |  Latency (cycles) |  Latency (absolute) |  Interval | Pipeline|
    |   min   |   max   |    min   |    max   | min | max |   Type  |
    +---------+---------+----------+----------+-----+-----+---------+
    |      889|      889|  8.890 us|  8.890 us|  889|  889|       no|
    +---------+---------+----------+----------+-----+-----+---------+

    + Detail: 
        * Instance: 
        +--------------------------------------------------------------------+----------------------------------------------------------+---------+---------+----------+----------+-----+-----+---------+
        |                                                                    |                                                          |  Latency (cycles) |  Latency (absolute) |  Interval | Pipeline|
        |                              Instance                              |                          Module                          |   min   |   max   |    min   |    max   | min | max |   Type  |
        +--------------------------------------------------------------------+----------------------------------------------------------+---------+---------+----------+----------+-----+-----+---------+
        |grp_Attention_layer_Pipeline_VITIS_LOOP_64_1_VITIS_LOOP_65_2_fu_82  |Attention_layer_Pipeline_VITIS_LOOP_64_1_VITIS_LOOP_65_2  |      146|      146|  1.460 us|  1.460 us|  146|  146|       no|
        |grp_Attention_layer_Pipeline_l_gemm_i_outer_l_j_outer1_l_k1_fu_118  |Attention_layer_Pipeline_l_gemm_i_outer_l_j_outer1_l_k1   |      582|      582|  5.820 us|  5.820 us|  582|  582|       no|
        |grp_Attention_layer_Pipeline_l_norm_i2_l_j1_fu_146                  |Attention_layer_Pipeline_l_norm_i2_l_j1                   |      156|      156|  1.560 us|  1.560 us|  156|  156|       no|
        +--------------------------------------------------------------------+----------------------------------------------------------+---------+---------+----------+----------+-----+-----+---------+

        * Loop: 
        N/A

============================================================
+ Verbose Summary: Synthesis Manager
============================================================
InlineROM: 1
ExposeGlobal: 0
============================================================
+ Verbose Summary: CDFG Model
============================================================
IsTopModel: 0
ResetActiveHigh: 1
IsCombinational: 0
IsDatapathOnly: 0
HasWiredReturn: 1
HasMFsm: 0
HasVarLatency: 1
IsPipeline: 0
IsRtlPipelined: 0
IsInstanceOverlapped: 0
IsDontTouch: 0
HasImplIP: 0
IsGatedGlobalClock: 0


============================================================
+ Verbose Summary: Schedule
============================================================
* Number of FSM states : 6
* Pipeline : 0
* Dataflow Pipeline: 0

* FSM state transitions: 
1 --> 2 
2 --> 3 
3 --> 4 
4 --> 5 
5 --> 6 
6 --> 

* FSM state operations: 

State 1 <SV = 0> <Delay = 2.32>
ST_1 : Operation 7 [1/1] (2.32ns)   --->   "%outp_V = alloca i64 1" [kernel.cpp:63]   --->   Operation 7 'alloca' 'outp_V' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 8 [1/1] (2.32ns)   --->   "%outp_V_1 = alloca i64 1" [kernel.cpp:63]   --->   Operation 8 'alloca' 'outp_V_1' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 9 [1/1] (2.32ns)   --->   "%outp_V_2 = alloca i64 1" [kernel.cpp:63]   --->   Operation 9 'alloca' 'outp_V_2' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 10 [1/1] (2.32ns)   --->   "%outp_V_3 = alloca i64 1" [kernel.cpp:63]   --->   Operation 10 'alloca' 'outp_V_3' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 11 [1/1] (2.32ns)   --->   "%outp_V_4 = alloca i64 1" [kernel.cpp:63]   --->   Operation 11 'alloca' 'outp_V_4' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 12 [1/1] (2.32ns)   --->   "%outp_V_5 = alloca i64 1" [kernel.cpp:63]   --->   Operation 12 'alloca' 'outp_V_5' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 13 [1/1] (2.32ns)   --->   "%outp_V_6 = alloca i64 1" [kernel.cpp:63]   --->   Operation 13 'alloca' 'outp_V_6' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 14 [1/1] (2.32ns)   --->   "%outp_V_7 = alloca i64 1" [kernel.cpp:63]   --->   Operation 14 'alloca' 'outp_V_7' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 15 [1/1] (2.32ns)   --->   "%outp_V_8 = alloca i64 1" [kernel.cpp:63]   --->   Operation 15 'alloca' 'outp_V_8' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 16 [1/1] (2.32ns)   --->   "%outp_V_9 = alloca i64 1" [kernel.cpp:63]   --->   Operation 16 'alloca' 'outp_V_9' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 17 [1/1] (2.32ns)   --->   "%outp_V_10 = alloca i64 1" [kernel.cpp:63]   --->   Operation 17 'alloca' 'outp_V_10' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 18 [1/1] (2.32ns)   --->   "%outp_V_11 = alloca i64 1" [kernel.cpp:63]   --->   Operation 18 'alloca' 'outp_V_11' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 19 [1/1] (2.32ns)   --->   "%outp_V_12 = alloca i64 1" [kernel.cpp:63]   --->   Operation 19 'alloca' 'outp_V_12' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 20 [1/1] (2.32ns)   --->   "%outp_V_13 = alloca i64 1" [kernel.cpp:63]   --->   Operation 20 'alloca' 'outp_V_13' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 21 [1/1] (2.32ns)   --->   "%outp_V_14 = alloca i64 1" [kernel.cpp:63]   --->   Operation 21 'alloca' 'outp_V_14' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 22 [1/1] (2.32ns)   --->   "%outp_V_15 = alloca i64 1" [kernel.cpp:63]   --->   Operation 22 'alloca' 'outp_V_15' <Predicate = true> <Delay = 2.32>
ST_1 : Operation 23 [2/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_VITIS_LOOP_64_1_VITIS_LOOP_65_2, i24 %outp_V, i24 %outp_V_1, i24 %outp_V_2, i24 %outp_V_3, i24 %outp_V_4, i24 %outp_V_5, i24 %outp_V_6, i24 %outp_V_7, i24 %outp_V_8, i24 %outp_V_9, i24 %outp_V_10, i24 %outp_V_11, i24 %outp_V_12, i24 %outp_V_13, i24 %outp_V_14, i24 %outp_V_15"   --->   Operation 23 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 2 <SV = 1> <Delay = 0.00>
ST_2 : Operation 24 [1/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_VITIS_LOOP_64_1_VITIS_LOOP_65_2, i24 %outp_V, i24 %outp_V_1, i24 %outp_V_2, i24 %outp_V_3, i24 %outp_V_4, i24 %outp_V_5, i24 %outp_V_6, i24 %outp_V_7, i24 %outp_V_8, i24 %outp_V_9, i24 %outp_V_10, i24 %outp_V_11, i24 %outp_V_12, i24 %outp_V_13, i24 %outp_V_14, i24 %outp_V_15"   --->   Operation 24 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 3 <SV = 2> <Delay = 0.00>
ST_3 : Operation 25 [2/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_l_gemm_i_outer_l_j_outer1_l_k1, i24 %outp_V, i24 %outp_V_1, i24 %outp_V_2, i24 %outp_V_3, i24 %outp_V_4, i24 %outp_V_5, i24 %outp_V_6, i24 %outp_V_7, i24 %outp_V_8, i24 %outp_V_9, i24 %outp_V_10, i24 %outp_V_11, i24 %outp_V_12, i24 %outp_V_13, i24 %outp_V_14, i24 %outp_V_15, i24 %v20_0, i24 %v20_1, i24 %v21_0, i24 %v21_1"   --->   Operation 25 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 4 <SV = 3> <Delay = 0.00>
ST_4 : Operation 26 [1/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_l_gemm_i_outer_l_j_outer1_l_k1, i24 %outp_V, i24 %outp_V_1, i24 %outp_V_2, i24 %outp_V_3, i24 %outp_V_4, i24 %outp_V_5, i24 %outp_V_6, i24 %outp_V_7, i24 %outp_V_8, i24 %outp_V_9, i24 %outp_V_10, i24 %outp_V_11, i24 %outp_V_12, i24 %outp_V_13, i24 %outp_V_14, i24 %outp_V_15, i24 %v20_0, i24 %v20_1, i24 %v21_0, i24 %v21_1"   --->   Operation 26 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 5 <SV = 4> <Delay = 0.00>
ST_5 : Operation 27 [2/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_l_norm_i2_l_j1, i32 %v22, i24 %outp_V, i24 %outp_V_1, i24 %outp_V_2, i24 %outp_V_3, i24 %outp_V_4, i24 %outp_V_5, i24 %outp_V_6, i24 %outp_V_7, i24 %outp_V_8, i24 %outp_V_9, i24 %outp_V_10, i24 %outp_V_11, i24 %outp_V_12, i24 %outp_V_13, i24 %outp_V_14, i24 %outp_V_15"   --->   Operation 27 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 6 <SV = 5> <Delay = 0.00>
ST_6 : Operation 28 [1/2] (0.00ns)   --->   "%call_ln0 = call void @Attention_layer_Pipeline_l_norm_i2_l_j1, i32 %v22, i24 %outp_V, i24 %outp_V_1, i24 %outp_V_2, i24 %outp_V_3, i24 %outp_V_4, i24 %outp_V_5, i24 %outp_V_6, i24 %outp_V_7, i24 %outp_V_8, i24 %outp_V_9, i24 %outp_V_10, i24 %outp_V_11, i24 %outp_V_12, i24 %outp_V_13, i24 %outp_V_14, i24 %outp_V_15"   --->   Operation 28 'call' 'call_ln0' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >
ST_6 : Operation 29 [1/1] (0.00ns)   --->   "%ret_ln100 = ret" [kernel.cpp:100]   --->   Operation 29 'ret' 'ret_ln100' <Predicate = true> <Delay = 0.00>


============================================================
+ Verbose Summary: Binding
============================================================
STG Binding: 
---------------- STG Properties BEGIN ----------------
- Is combinational: 0
- Is one-state seq: 0
- Is datapath-only: 0
- Is pipelined: 0
- Is top level: 0
Port [ Return ] is wired: 1; IO mode=ap_ctrl_hs:ce=0
Port [ v20_0]:  wired=1; compound=1; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[11]; IO mode=ap_memory:ce=0
Port [ v20_1]:  wired=1; compound=1; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[11]; IO mode=ap_memory:ce=0
Port [ v21_0]:  wired=1; compound=1; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[11]; IO mode=ap_memory:ce=0
Port [ v21_1]:  wired=1; compound=1; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[11]; IO mode=ap_memory:ce=0
Port [ v22]:  wired=1; compound=1; hidden=0; nouse=0; global=0; static=0; extern=0; dir=1; type=1; pingpong=0; private_global=0; MemPort=[03]; IO mode=ap_memory:ce=0
---------------- STG Properties END ------------------

---------------- Datapath Model BEGIN ----------------

<LifeTime>
<method=bitvector/>
outp_V    (alloca) [ 0011111]
outp_V_1  (alloca) [ 0011111]
outp_V_2  (alloca) [ 0011111]
outp_V_3  (alloca) [ 0011111]
outp_V_4  (alloca) [ 0011111]
outp_V_5  (alloca) [ 0011111]
outp_V_6  (alloca) [ 0011111]
outp_V_7  (alloca) [ 0011111]
outp_V_8  (alloca) [ 0011111]
outp_V_9  (alloca) [ 0011111]
outp_V_10 (alloca) [ 0011111]
outp_V_11 (alloca) [ 0011111]
outp_V_12 (alloca) [ 0011111]
outp_V_13 (alloca) [ 0011111]
outp_V_14 (alloca) [ 0011111]
outp_V_15 (alloca) [ 0011111]
call_ln0  (call  ) [ 0000000]
call_ln0  (call  ) [ 0000000]
call_ln0  (call  ) [ 0000000]
ret_ln100 (ret   ) [ 0000000]
</LifeTime>

<model>

<comp_list>
<comp id="0" class="1000" name="v20_0">
<pin_list>
<pin id="1" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="v20_0"/><MemPortTyVec>1 1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="2" class="1000" name="v20_1">
<pin_list>
<pin id="3" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="v20_1"/><MemPortTyVec>1 1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="4" class="1000" name="v21_0">
<pin_list>
<pin id="5" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="v21_0"/><MemPortTyVec>1 1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="6" class="1000" name="v21_1">
<pin_list>
<pin id="7" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="v21_1"/><MemPortTyVec>1 1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="8" class="1000" name="v22">
<pin_list>
<pin id="9" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="v22"/><MemPortTyVec>0 3 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="10" class="1001" name="const_10">
<pin_list>
<pin id="11" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="12" class="1001" name="const_12">
<pin_list>
<pin id="13" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="Attention_layer_Pipeline_VITIS_LOOP_64_1_VITIS_LOOP_65_2"/></StgValue>
</bind>
</comp>

<comp id="14" class="1001" name="const_14">
<pin_list>
<pin id="15" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="Attention_layer_Pipeline_l_gemm_i_outer_l_j_outer1_l_k1"/></StgValue>
</bind>
</comp>

<comp id="16" class="1001" name="const_16">
<pin_list>
<pin id="17" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="Attention_layer_Pipeline_l_norm_i2_l_j1"/></StgValue>
</bind>
</comp>

<comp id="18" class="1004" name="outp_V_alloca_fu_18">
<pin_list>
<pin id="19" dir="0" index="0" bw="1" slack="0"/>
<pin id="20" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V/1 "/>
</bind>
</comp>

<comp id="22" class="1004" name="outp_V_1_alloca_fu_22">
<pin_list>
<pin id="23" dir="0" index="0" bw="1" slack="0"/>
<pin id="24" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_1/1 "/>
</bind>
</comp>

<comp id="26" class="1004" name="outp_V_2_alloca_fu_26">
<pin_list>
<pin id="27" dir="0" index="0" bw="1" slack="0"/>
<pin id="28" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_2/1 "/>
</bind>
</comp>

<comp id="30" class="1004" name="outp_V_3_alloca_fu_30">
<pin_list>
<pin id="31" dir="0" index="0" bw="1" slack="0"/>
<pin id="32" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_3/1 "/>
</bind>
</comp>

<comp id="34" class="1004" name="outp_V_4_alloca_fu_34">
<pin_list>
<pin id="35" dir="0" index="0" bw="1" slack="0"/>
<pin id="36" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_4/1 "/>
</bind>
</comp>

<comp id="38" class="1004" name="outp_V_5_alloca_fu_38">
<pin_list>
<pin id="39" dir="0" index="0" bw="1" slack="0"/>
<pin id="40" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_5/1 "/>
</bind>
</comp>

<comp id="42" class="1004" name="outp_V_6_alloca_fu_42">
<pin_list>
<pin id="43" dir="0" index="0" bw="1" slack="0"/>
<pin id="44" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_6/1 "/>
</bind>
</comp>

<comp id="46" class="1004" name="outp_V_7_alloca_fu_46">
<pin_list>
<pin id="47" dir="0" index="0" bw="1" slack="0"/>
<pin id="48" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_7/1 "/>
</bind>
</comp>

<comp id="50" class="1004" name="outp_V_8_alloca_fu_50">
<pin_list>
<pin id="51" dir="0" index="0" bw="1" slack="0"/>
<pin id="52" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_8/1 "/>
</bind>
</comp>

<comp id="54" class="1004" name="outp_V_9_alloca_fu_54">
<pin_list>
<pin id="55" dir="0" index="0" bw="1" slack="0"/>
<pin id="56" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_9/1 "/>
</bind>
</comp>

<comp id="58" class="1004" name="outp_V_10_alloca_fu_58">
<pin_list>
<pin id="59" dir="0" index="0" bw="1" slack="0"/>
<pin id="60" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_10/1 "/>
</bind>
</comp>

<comp id="62" class="1004" name="outp_V_11_alloca_fu_62">
<pin_list>
<pin id="63" dir="0" index="0" bw="1" slack="0"/>
<pin id="64" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_11/1 "/>
</bind>
</comp>

<comp id="66" class="1004" name="outp_V_12_alloca_fu_66">
<pin_list>
<pin id="67" dir="0" index="0" bw="1" slack="0"/>
<pin id="68" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_12/1 "/>
</bind>
</comp>

<comp id="70" class="1004" name="outp_V_13_alloca_fu_70">
<pin_list>
<pin id="71" dir="0" index="0" bw="1" slack="0"/>
<pin id="72" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_13/1 "/>
</bind>
</comp>

<comp id="74" class="1004" name="outp_V_14_alloca_fu_74">
<pin_list>
<pin id="75" dir="0" index="0" bw="1" slack="0"/>
<pin id="76" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_14/1 "/>
</bind>
</comp>

<comp id="78" class="1004" name="outp_V_15_alloca_fu_78">
<pin_list>
<pin id="79" dir="0" index="0" bw="1" slack="0"/>
<pin id="80" dir="1" index="1" bw="24" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="outp_V_15/1 "/>
</bind>
</comp>

<comp id="82" class="1004" name="grp_Attention_layer_Pipeline_VITIS_LOOP_64_1_VITIS_LOOP_65_2_fu_82">
<pin_list>
<pin id="83" dir="0" index="0" bw="0" slack="0"/>
<pin id="84" dir="0" index="1" bw="24" slack="0"/>
<pin id="85" dir="0" index="2" bw="24" slack="0"/>
<pin id="86" dir="0" index="3" bw="24" slack="0"/>
<pin id="87" dir="0" index="4" bw="24" slack="0"/>
<pin id="88" dir="0" index="5" bw="24" slack="0"/>
<pin id="89" dir="0" index="6" bw="24" slack="0"/>
<pin id="90" dir="0" index="7" bw="24" slack="0"/>
<pin id="91" dir="0" index="8" bw="24" slack="0"/>
<pin id="92" dir="0" index="9" bw="24" slack="0"/>
<pin id="93" dir="0" index="10" bw="24" slack="0"/>
<pin id="94" dir="0" index="11" bw="24" slack="0"/>
<pin id="95" dir="0" index="12" bw="24" slack="0"/>
<pin id="96" dir="0" index="13" bw="24" slack="0"/>
<pin id="97" dir="0" index="14" bw="24" slack="0"/>
<pin id="98" dir="0" index="15" bw="24" slack="0"/>
<pin id="99" dir="0" index="16" bw="24" slack="0"/>
<pin id="100" dir="1" index="17" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/1 "/>
</bind>
</comp>

<comp id="118" class="1004" name="grp_Attention_layer_Pipeline_l_gemm_i_outer_l_j_outer1_l_k1_fu_118">
<pin_list>
<pin id="119" dir="0" index="0" bw="0" slack="0"/>
<pin id="120" dir="0" index="1" bw="24" slack="2147483647"/>
<pin id="121" dir="0" index="2" bw="24" slack="2147483647"/>
<pin id="122" dir="0" index="3" bw="24" slack="2147483647"/>
<pin id="123" dir="0" index="4" bw="24" slack="2147483647"/>
<pin id="124" dir="0" index="5" bw="24" slack="2147483647"/>
<pin id="125" dir="0" index="6" bw="24" slack="2147483647"/>
<pin id="126" dir="0" index="7" bw="24" slack="2147483647"/>
<pin id="127" dir="0" index="8" bw="24" slack="2147483647"/>
<pin id="128" dir="0" index="9" bw="24" slack="2147483647"/>
<pin id="129" dir="0" index="10" bw="24" slack="2147483647"/>
<pin id="130" dir="0" index="11" bw="24" slack="2147483647"/>
<pin id="131" dir="0" index="12" bw="24" slack="2147483647"/>
<pin id="132" dir="0" index="13" bw="24" slack="2147483647"/>
<pin id="133" dir="0" index="14" bw="24" slack="2147483647"/>
<pin id="134" dir="0" index="15" bw="24" slack="2147483647"/>
<pin id="135" dir="0" index="16" bw="24" slack="2147483647"/>
<pin id="136" dir="0" index="17" bw="24" slack="0"/>
<pin id="137" dir="0" index="18" bw="24" slack="0"/>
<pin id="138" dir="0" index="19" bw="24" slack="0"/>
<pin id="139" dir="0" index="20" bw="24" slack="0"/>
<pin id="140" dir="1" index="21" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/3 "/>
</bind>
</comp>

<comp id="146" class="1004" name="grp_Attention_layer_Pipeline_l_norm_i2_l_j1_fu_146">
<pin_list>
<pin id="147" dir="0" index="0" bw="0" slack="0"/>
<pin id="148" dir="0" index="1" bw="32" slack="0"/>
<pin id="149" dir="0" index="2" bw="24" slack="2147483647"/>
<pin id="150" dir="0" index="3" bw="24" slack="2147483647"/>
<pin id="151" dir="0" index="4" bw="24" slack="2147483647"/>
<pin id="152" dir="0" index="5" bw="24" slack="2147483647"/>
<pin id="153" dir="0" index="6" bw="24" slack="2147483647"/>
<pin id="154" dir="0" index="7" bw="24" slack="2147483647"/>
<pin id="155" dir="0" index="8" bw="24" slack="2147483647"/>
<pin id="156" dir="0" index="9" bw="24" slack="2147483647"/>
<pin id="157" dir="0" index="10" bw="24" slack="2147483647"/>
<pin id="158" dir="0" index="11" bw="24" slack="2147483647"/>
<pin id="159" dir="0" index="12" bw="24" slack="2147483647"/>
<pin id="160" dir="0" index="13" bw="24" slack="2147483647"/>
<pin id="161" dir="0" index="14" bw="24" slack="2147483647"/>
<pin id="162" dir="0" index="15" bw="24" slack="2147483647"/>
<pin id="163" dir="0" index="16" bw="24" slack="2147483647"/>
<pin id="164" dir="0" index="17" bw="24" slack="2147483647"/>
<pin id="165" dir="1" index="18" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/5 "/>
</bind>
</comp>

</comp_list>

<net_list>
<net id="21"><net_src comp="10" pin="0"/><net_sink comp="18" pin=0"/></net>

<net id="25"><net_src comp="10" pin="0"/><net_sink comp="22" pin=0"/></net>

<net id="29"><net_src comp="10" pin="0"/><net_sink comp="26" pin=0"/></net>

<net id="33"><net_src comp="10" pin="0"/><net_sink comp="30" pin=0"/></net>

<net id="37"><net_src comp="10" pin="0"/><net_sink comp="34" pin=0"/></net>

<net id="41"><net_src comp="10" pin="0"/><net_sink comp="38" pin=0"/></net>

<net id="45"><net_src comp="10" pin="0"/><net_sink comp="42" pin=0"/></net>

<net id="49"><net_src comp="10" pin="0"/><net_sink comp="46" pin=0"/></net>

<net id="53"><net_src comp="10" pin="0"/><net_sink comp="50" pin=0"/></net>

<net id="57"><net_src comp="10" pin="0"/><net_sink comp="54" pin=0"/></net>

<net id="61"><net_src comp="10" pin="0"/><net_sink comp="58" pin=0"/></net>

<net id="65"><net_src comp="10" pin="0"/><net_sink comp="62" pin=0"/></net>

<net id="69"><net_src comp="10" pin="0"/><net_sink comp="66" pin=0"/></net>

<net id="73"><net_src comp="10" pin="0"/><net_sink comp="70" pin=0"/></net>

<net id="77"><net_src comp="10" pin="0"/><net_sink comp="74" pin=0"/></net>

<net id="81"><net_src comp="10" pin="0"/><net_sink comp="78" pin=0"/></net>

<net id="101"><net_src comp="12" pin="0"/><net_sink comp="82" pin=0"/></net>

<net id="102"><net_src comp="18" pin="1"/><net_sink comp="82" pin=1"/></net>

<net id="103"><net_src comp="22" pin="1"/><net_sink comp="82" pin=2"/></net>

<net id="104"><net_src comp="26" pin="1"/><net_sink comp="82" pin=3"/></net>

<net id="105"><net_src comp="30" pin="1"/><net_sink comp="82" pin=4"/></net>

<net id="106"><net_src comp="34" pin="1"/><net_sink comp="82" pin=5"/></net>

<net id="107"><net_src comp="38" pin="1"/><net_sink comp="82" pin=6"/></net>

<net id="108"><net_src comp="42" pin="1"/><net_sink comp="82" pin=7"/></net>

<net id="109"><net_src comp="46" pin="1"/><net_sink comp="82" pin=8"/></net>

<net id="110"><net_src comp="50" pin="1"/><net_sink comp="82" pin=9"/></net>

<net id="111"><net_src comp="54" pin="1"/><net_sink comp="82" pin=10"/></net>

<net id="112"><net_src comp="58" pin="1"/><net_sink comp="82" pin=11"/></net>

<net id="113"><net_src comp="62" pin="1"/><net_sink comp="82" pin=12"/></net>

<net id="114"><net_src comp="66" pin="1"/><net_sink comp="82" pin=13"/></net>

<net id="115"><net_src comp="70" pin="1"/><net_sink comp="82" pin=14"/></net>

<net id="116"><net_src comp="74" pin="1"/><net_sink comp="82" pin=15"/></net>

<net id="117"><net_src comp="78" pin="1"/><net_sink comp="82" pin=16"/></net>

<net id="141"><net_src comp="14" pin="0"/><net_sink comp="118" pin=0"/></net>

<net id="142"><net_src comp="0" pin="0"/><net_sink comp="118" pin=17"/></net>

<net id="143"><net_src comp="2" pin="0"/><net_sink comp="118" pin=18"/></net>

<net id="144"><net_src comp="4" pin="0"/><net_sink comp="118" pin=19"/></net>

<net id="145"><net_src comp="6" pin="0"/><net_sink comp="118" pin=20"/></net>

<net id="166"><net_src comp="16" pin="0"/><net_sink comp="146" pin=0"/></net>

<net id="167"><net_src comp="8" pin="0"/><net_sink comp="146" pin=1"/></net>

</net_list>

</model> 
---------------- Datapath Model END ------------------

* FSMD analyzer results:
  - Output states:
	Port: v22 | {5 6 }
 - Input state : 
	Port: Attention_layer : v20_0 | {3 4 }
	Port: Attention_layer : v20_1 | {3 4 }
	Port: Attention_layer : v21_0 | {3 4 }
	Port: Attention_layer : v21_1 | {3 4 }
  - Chain level:
	State 1
		call_ln0 : 1
	State 2
	State 3
	State 4
	State 5
	State 6


============================================================
+ Verbose Summary: Datapath Resource usage 
============================================================

* Functional unit list:
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
| Operation|                           Functional Unit                          |   DSP   |  Delay  |    FF   |   LUT   |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|          | grp_Attention_layer_Pipeline_VITIS_LOOP_64_1_VITIS_LOOP_65_2_fu_82 |    0    |    0    |    24   |    83   |
|   call   | grp_Attention_layer_Pipeline_l_gemm_i_outer_l_j_outer1_l_k1_fu_118 |    64   |  88.928 |   6680  |   3317  |
|          |         grp_Attention_layer_Pipeline_l_norm_i2_l_j1_fu_146         |    3    |  26.996 |   522   |   1427  |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|   Total  |                                                                    |    67   | 115.924 |   7226  |   4827  |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|

Memories:
+---------+--------+--------+--------+--------+
|         |  BRAM  |   FF   |   LUT  |  URAM  |
+---------+--------+--------+--------+--------+
|  outp_V |    0   |   48   |    4   |    0   |
| outp_V_1|    0   |   48   |    4   |    0   |
|outp_V_10|    0   |   48   |    4   |    0   |
|outp_V_11|    0   |   48   |    4   |    0   |
|outp_V_12|    0   |   48   |    4   |    0   |
|outp_V_13|    0   |   48   |    4   |    0   |
|outp_V_14|    0   |   48   |    4   |    0   |
|outp_V_15|    0   |   48   |    4   |    0   |
| outp_V_2|    0   |   48   |    4   |    0   |
| outp_V_3|    0   |   48   |    4   |    0   |
| outp_V_4|    0   |   48   |    4   |    0   |
| outp_V_5|    0   |   48   |    4   |    0   |
| outp_V_6|    0   |   48   |    4   |    0   |
| outp_V_7|    0   |   48   |    4   |    0   |
| outp_V_8|    0   |   48   |    4   |    0   |
| outp_V_9|    0   |   48   |    4   |    0   |
+---------+--------+--------+--------+--------+
|  Total  |    0   |   768  |   64   |    0   |
+---------+--------+--------+--------+--------+

* Register list:
N/A

* Multiplexer (MUX) list: 
|--------|------|------|------|--------|
|  Comp  |  Pin | Size |  BW  | S x BW |
|--------|------|------|------|--------|
|  Total |      |      |      |    0   |
|--------|------|------|------|--------|



* Summary:
+-----------+--------+--------+--------+--------+--------+--------+
|           |  BRAM  |   DSP  |  Delay |   FF   |   LUT  |  URAM  |
+-----------+--------+--------+--------+--------+--------+--------+
|  Function |    -   |   67   |   115  |  7226  |  4827  |    -   |
|   Memory  |    0   |    -   |    -   |   768  |   64   |    0   |
|Multiplexer|    -   |    -   |    -   |    -   |    -   |    -   |
|  Register |    -   |    -   |    -   |    -   |    -   |    -   |
+-----------+--------+--------+--------+--------+--------+--------+
|   Total   |    0   |   67   |   115  |  7994  |  4891  |    0   |
+-----------+--------+--------+--------+--------+--------+--------+
